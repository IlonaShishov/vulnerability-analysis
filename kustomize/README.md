# Procedure to Deploy

1. Set all your api keys and tokens in the following command. Note that all the keys are not required.
Look at this [Readme](../README.md) for more details.

```shell
cat > base/secrets.env << EOF
nvd_api_key=you_api_key
serpapi_api_key=your_api_key
tavily_api_key=your_api_key
nvidia_api_key=your_api_key
ghsa_api_key=your_api_key
ngc_api_key=your_api_key
EOF
```

2. If you don't have namespace , create it
```shell
export YOUR_NAMESPACE_NAME=yourNamespaceNameHere
oc new-project $YOUR_NAMESPACE_NAME
```

3. Create an image pull secret that is authorized to pull agent morpheus image:      
```shell
oc create secret generic morpheus-pull-secret --from-file=.dockerconfigjson=<path/to/.docker/config.json> --type=kubernetes.io/dockerconfigjson
```

4. Create an image pull secret that is authorized to pull images from ngrc.io:      
```shell
oc create secret generic ngrc-secret --from-file=.dockerconfigjson=<path/to/.docker/config.json> --type=kubernetes.io/dockerconfigjson
```

5. Deploy agent-morpheus + agent-morpheus-client to your namespace
```shell
oc kustomize overlays/nvidia-llm-service |  oc apply -f - -n $YOUR_NAMESPACE_NAME
```

6. Alternatively, if you want to deploy agent-morpheus with our self-hosted LLM, then run
```shell
# Enable ingress traffic into our LLM Model service in the cluster
oc apply -f network-policy.yaml
# label namespace with application=agent-morpheus to open communication from your namespace to LLM Model service on our Cluster 
oc label namespace $YOUR_NAMESPACE_NAME application=agent-morpheus
# Deploy agent-morpheus integrated with our self-hosted LLM
oc kustomize overlays/our-llm-service |  oc apply -f - -n $YOUR_NAMESPACE_NAME
```
7. Deploy self-hosted Llama-3.1-8b LLM
    1. Clone the following repo
     ```shell
    clone git@github.com:zvigrinberg/nim-deploy.git
    cd nim-deploy/helm
     ```
    2. Create new namespace
    ```shell
    oc new-project nim 
    ```
    3. Create service account for the deployment
    ```shell
    export SERVICE_ACCOUNT_NAME=nim-llm-sa
    oc create serviceaccount $SERVICE_ACCOUNT_NAME
    ```
    4. add `anyuid` `SecurityContextConstraint` privilege to the created service account
    ```shell
       oc adm policy add-scc-to-user -z $SERVICE_ACCOUNT_NAME anyuid
    ```
    5. Deploy the chart
   ```shell
    helm install nim-llm nim-llm/ --set persistence.enabled=true \
    --set model.ngcAPIKey=$NGC_API_KEY \
    --set image.repository=nvcr.io/nim/meta/llama-3.1-8b-instruct \
    --set image.tag=latest \
    --set serviceAccount.name=$SERVICE_ACCOUNT_NAME \
    --set tolerations[0].key=p4-gpu \
    --set tolerations[0].operator=Exists \
    --set tolerations[0].effect=NoSchedule
   ```