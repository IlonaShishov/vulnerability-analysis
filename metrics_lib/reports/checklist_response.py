
class ChecklistResponseMetrics:
    
    def __init__(self):

        self.name = "Checklist Response Metrics"

        self.metrics = {
            "SemanticSimilarity": {},
            "LLMContextPrecisionWithoutReference": {},
            "LLMContextRecall": {},
            "Faithfulness": {},
            "ResponseRelevancy": {},
            "SummarizationScore": {},
            "AspectCritic_relevance": { 
                "name": "*aspect_critic_relevance", 
                "definition": "Does the submission directly and fully address the task without introducing unrelated or unnecessary information?"
            },
            "AspectCritic_completeness": { 
                "name": "*aspect_critic_completeness",
                "definition": "Does the submission provide all necessary information to fully address the task? Does it avoid missing key details?"
            },
            "AspectCritic_format_compliance": { 
                "name": "*aspect_critic_format_compliance",
                "definition": "Does the submission report research findings rather than providing instructions or step-by-step guidance?"
            },
            "AspectCritic_conciseness": { 
                "name": "*aspect_critic_conciseness",
                "definition": "Is the submission clear and to the point, avoiding unnecessary repetition or excessive verbosity?"
            },
            "AspectCritic_coherence": { 
                "name": "*aspect_critic_coherence",
                "definition": "Is the submission well-structured and logically connected, making it easy to understand and follow?"
            }
        }

    def get_datasets(self, test_data):
        datasets = {}
        for case_id, case_data in test_data.items():
            dataset = []
            for item in case_data:   
                output = item["output"] 
                for check in output["checklist"]:
                    answer = check["response"]
                    question = check["input"]
                    thought_process_result_lst = [step["tool_output"] for step in check["intermediate_steps"]]
                    thought_process_result_str = ', '.join(thought_process_result_lst)
                    data = {
                        "user_input": question,
                        "response": answer,
                        "reference": thought_process_result_str,
                        "reference_contexts": thought_process_result_lst,
                        "retrieved_contexts": thought_process_result_lst
                    }
                    dataset.append(data)
            datasets[case_id] = dataset
        return datasets
