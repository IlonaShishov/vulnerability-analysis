import pandas as pd

from src.cve.nodes.cve_justification_node import CVEJustifyNode

class JustificationLabelMetrics:
 
    def __init__(self):

        self.name = "Justification Label Metrics"

        self.metrics = {
            "AspectCritic_consistency": { 
                "name": "*aspect_critic_consistency", 
                "definition": "Is the reasoning in the submission consistent with the summary provided in the prompt and does not introduce contradictions or inaccuracies?"
            },
            "AspectCritic_relevance": { 
                "name": "*aspect_critic_relevance",
                "definition": "Is the selected category name in the submission relevant to the summary provided in the prompt, focusing on its most important aspects?"
            },
            "AspectCritic_validity": { 
                "name": "*aspect_critic_validity",
                "definition": "Does the selected category name in the submission exactly match one of the predefined valid categories names listed in the prompt?"
            },
            "AspectCritic_justification": { 
                "name": "*aspect_critic_justification", 
                "definition": "In the submission, does the reasoning logically justify the selected category name, considering the information provided in the summary within the prompt?"
            }
        }

    def get_datasets(self, test_data):
        datasets = {}
        for case_id, case_data in test_data.items():
            dataset = []
            for item in case_data:   
                output = item["output"] 
                justification_label = output["justification"]["label"]
                justification_reason = output["justification"]["reason"]
                summary = output["summary"]
                data = {
                    "user_input": CVEJustifyNode.JUSTIFICATION_PROMPT.format(summary=summary),
                    "response": f'{justification_label}\n{justification_reason}',
                    "reference": summary,
                    "reference_contexts": [summary],
                    "retrieved_contexts": [summary]
                }
                dataset.append(data)
            datasets[case_id] = dataset
        return datasets

class VulnerabilityConsistencyReport:
    
    def __init__(self, test_data):
        self.name = "Vulnerability Consistency"
        
        self.data = test_data
        self.report_table = pd.DataFrame({'ID': list(self.data.keys())})

        self._evaluate()

    def _evaluate(self):
        for case_id, case_data in self.data.items():
            affected_count = 0
            unknown_count = 0
            not_affected_count = 0
            for idx, item in enumerate(case_data):
                output = item["output"]
                label = output["justification"]["label"]
                match label:
                    case "vulnerable":
                        self.report_table.loc[self.report_table['ID'] == case_id, f'OP{idx + 1}'] = "Affected"
                        affected_count+=1
                    case "uncertain":
                        self.report_table.loc[self.report_table['ID'] == case_id, f'OP{idx + 1}'] = "Unknown"
                        unknown_count+=1
                    case _:
                        self.report_table.loc[self.report_table['ID'] == case_id, f'OP{idx + 1}'] = "Not Affected"
                        not_affected_count+=1
            total_count = affected_count + not_affected_count + unknown_count
            self.report_table.loc[self.report_table['ID'] == case_id, 'Answer Consistency'] = max(
                    affected_count, not_affected_count, unknown_count
                ) / total_count

class JustificationLabelConsistencyReport:
    
    def __init__(self, test_data):
        self.name = "Justification Label Consistency"

        self.data = test_data
        self.report_table = pd.DataFrame({'ID': list(self.data.keys())})
        
        self._evaluate()

    def _evaluate(self):
        for case_id, case_data in self.data.items():
            label_count = {}
            for idx, item in enumerate(case_data):
                output = item["output"]
                label = output["justification"]["label"]
                self.report_table.loc[self.report_table['ID'] == case_id, f'OP{idx + 1}'] = label
                label_count[label] = label_count.get(label, 0) + 1
            self.report_table.loc[self.report_table['ID'] == case_id, 'Answer Consistency'] = max(label_count.values()) / sum(label_count.values())