# SPDX-FileCopyrightText: Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import fnmatch
from io import BytesIO
import logging
import os
import shutil
import typing
from pathlib import Path
from zipfile import ZipFile

from langchain_community.document_loaders.blob_loaders.schema import BlobLoader
from langchain_core.document_loaders.blob_loaders import Blob
import requests
from tqdm import tqdm

PathLike = typing.Union[str, os.PathLike]

logger = logging.getLogger(__name__)


class SourceCodeArtifactLoader(BlobLoader):
    """
    Load `Artifact` source files.

    The Artifact can be local on disk available at `local_path`,
    or remote at `remote_path` that will be cloned to `local_path`.
    Currently, supports only text files.

    Each document represents one file. The `local_path` points to
    the local extracted artifact folder.
    """

    def __init__(
        self,
        local_path: PathLike,
        remote_path: str | None = None,
        compression: str | None = None,
        include: typing.Optional[typing.Iterable[str]] = None,
        exclude: typing.Optional[typing.Iterable[str]] = None,
    ):
        """
        Initialize the Git loader.

        Parameters
        ----------
        local_path : PathLike
            Path to the local extracted artifact.
        remote_path : str | None, optional
            URL to the remote Artifact to be downloaded and extracted, by default None
        compression : compression type of the artifact
        include : typing.Optional[typing.Iterable[str]], optional
            A list of file patterns to include. Uses the glob syntax, by default None
        exclude : typing.Optional[typing.Iterable[str]], optional
            A list of file patterns to exclude. Uses the glob syntax, by default None
        """

        self.local_path = Path(local_path)
        self.remote_path = remote_path
        self.compression = compression

        self.include = include
        self.exclude = exclude


    def load_artifact(self):
        """
        Downloads the Artifact and return the location of the extracted artifact folder.

        Returns
        -------
        str
            Location of the extracted folder.

        Raises
        ------
        ValueError
            If only the path is provided but does not exist.
        """

        if not os.path.exists(self.local_path) and self.remote_path is None:
            raise ValueError(f"Path {self.local_path} does not exist")
 
        elif self.remote_path:
            if not os.path.isdir(self.local_path):
                logger.debug("Downloading artifact from URL: '%s'", self.remote_path)
                
                with requests.get(self.remote_path, stream=True) as remote_source:
                    if self.compression == "zip":
                        with ZipFile(BytesIO(remote_source.content)) as zfile:
                            zfile.extractall(self.local_path)

                            subdirs = os.listdir(self.local_path)
                            if len(subdirs) == 1:
                                src_dir = os.path.join(self.local_path, subdirs[0])
                                contents = os.listdir(src_dir)
                                for f in contents:
                                    src_path = os.path.join(src_dir, f)
                                    shutil.move(src_path, os.path.join(self.local_path, f))
                    else:
                        raise ValueError(f"Unsupported compression type {self.compression}")

                logger.debug("Loaded Artifact at path: '%s' ", self.local_path)

        else:
            logger.debug("Using existing Artifact at path: '%s'", self.local_path)

        return self.local_path

    def yield_blobs(self) -> typing.Iterator[Blob]:
        """
        Yield the blobs from the downloaded artifact folder. The retrieved files will be
        filtered using the includes and excludes expressions.

        Returns
        -------
        typing.Iterator[Blob]
            An iterator of `Blob` objects representing the files in the local folder.

        Yields
        ------
        Iterator[typing.Iterator[Blob]]
            An iterator of `Blob` objects representing the files in the local folder.
        """

        path = self.load_artifact()

        logger.debug("Scanning documents for path: '%s'", path)

        base_path = Path(path)

        final_files = []

        for include_pattern in self.include:
            for file in base_path.rglob(include_pattern):
                rel_file = file.relative_to(path)
                # If the file matches any exclude pattern, skip it
                if file.is_file() and not any(fnmatch.fnmatch(str(rel_file), exclude_pattern) for exclude_pattern in self.exclude):
                    final_files.append(rel_file)

        for f in tqdm(final_files):

            file_path = Path(f)

            abs_file_path = base_path / file_path

            rel_file_path = str(file_path)

            metadata = {
                "source": rel_file_path,
                "file_path": rel_file_path,
                "file_name": file_path.name,
                "file_type": file_path.suffix,
            }

            yield Blob.from_path(abs_file_path, metadata=metadata)
