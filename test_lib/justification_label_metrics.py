
from ragas.dataset_schema import SingleTurnSample

class JustificationLabelMetrics:
 
    def __init__(self):

        self.metrics = {
            "faithfulness": {
                "scorer_class": "Faithfulness",
                "name": "faithfulness",
                "sample_type": "single_turn_samples",
                "llm": True,
            },
            "response_relevancy": {
                "scorer_class": "ResponseRelevancy",
                "name": "response_relevancy",
                "sample_type": "single_turn_samples",
                "embeddings": True,
                "llm": True,
            },
            "summarization": {
                "scorer_class": "SummarizationScore",
                "name": "summarization",
                "sample_type": "single_turn_samples",
                "llm": True,
            },
            "aspect_critic_accuracy": {
                "scorer_class": "AspectCritic",
                "name": "aspect_critic_accuracy",
                "sample_type": "single_turn_samples",
                "llm": True,
                "kwargs": {
                    "definition": "Does the justification label accurately reflect the content and details in the summary without introducing incorrect, unsupported, or contradictory information?"
                }
            },
            "aspect_critic_relevance": {
                "scorer_class": "AspectCritic",
                "name": "aspect_critic_relevance",
                "sample_type": "single_turn_samples",
                "llm": True,
                "kwargs": {
                    "definition": "Does the justification label align with the primary themes, objectives, or key elements of the summary, avoiding off-topic or unrelated content?"
                }
            }
        }


    def get_single_turn_samples(self, data):
        single_turn_samples = {}
        for case_id, outputs in data.items():
            samples = []
            for output in outputs:    
                checklist = [item["response"] for item in output["checklist"]]
                sample = SingleTurnSample(
                    user_input="Given the checklist as context and the summary as a reference, evaluate whether the justification label provided in the response is suitable and aligns with both.",
                    response=output["justification"]["label"],
                    reference=output["summary"],
                    reference_contexts=[output["summary"]],
                    retrieved_contexts=checklist
                )
                samples.append(sample)
            single_turn_samples[case_id] = samples
        return single_turn_samples
