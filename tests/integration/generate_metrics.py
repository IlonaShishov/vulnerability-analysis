import pytest
import pandas as pd
import os

from test_lib.data_loader import load_test_data
from test_lib.consistency_metrics import exploitability_consistency_check, justification_label_consistency_check
from test_lib.summary_metrics import SummaryMetrics
from test_lib.justification_label_metrics import JustificationLabelMetrics
from test_lib.metrics_generator import MetricsGenerator

@pytest.fixture
def test_data():
    examples_dir = os.getenv("EXAMPLES_DIR")
    return load_test_data(examples_dir)

@pytest.mark.asyncio
async def test_consistency_metrics(test_data):

    print ()
    print ("Agent Morpheus Exploitability Consistency Chart")

    exploitability_consistency_chart = exploitability_consistency_check(test_data)    
    
    print(exploitability_consistency_chart)

    print ()
    print ("Agent Morpheus Justification Label Consistency Chart")

    justification_label_consistency_chart = justification_label_consistency_check(test_data)    
    
    print(justification_label_consistency_chart)


@pytest.mark.asyncio
async def test_summary_metrics(test_data):

    summary_metrics = SummaryMetrics()
    metrics_generator = MetricsGenerator(test_data, summary_metrics)

    print()
    print("Agent Morpheus Summary Metrics")
    
    await metrics_generator.semantic_similarity
    await metrics_generator.context_precision
    await metrics_generator.context_recall
    await metrics_generator.faithfulness
    await metrics_generator.response_relevancy
    await metrics_generator.summarization

    print(metrics_generator.metrics_table)

@pytest.mark.asyncio
async def test_justification_label_metrics(test_data):

    justification_label_metrics = JustificationLabelMetrics()
    metrics_generator = MetricsGenerator(test_data, justification_label_metrics)

    print()
    print("Agent Morpheus Justification Label Metrics")

    await metrics_generator.faithfulness
    await metrics_generator.summarization
    await metrics_generator.response_relevancy
    await metrics_generator.aspect_critic_accuracy
    await metrics_generator.aspect_critic_relevance

    print(metrics_generator.metrics_table)
    